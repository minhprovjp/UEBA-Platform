import mysql.connector
import csv
import time
import uuid
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import sys

# --- C·∫§U H√åNH T·ªêC ƒê·ªò CAO ---
SCENARIO_FILE = "simulation/scenario_script_1day.csv"
FINAL_DATASET = "final_dataset_1day.csv"
DB_CONFIG = {"user": "root",
             "password": "root",
             "host": "localhost",
             "database": "mysql"}

# Tinh ch·ªânh hi·ªáu nƒÉng
NUM_THREADS = 20      # 20 lu·ªìng
BATCH_SIZE = 100      # 100 query/l√¥

# --- BI·∫æN TO√ÄN C·ª§C & C·ªú D·ª™NG ---
print_lock = threading.Lock()
total_processed = 0
stop_event = threading.Event() # <--- C√ÅI PHANH KH·∫®N C·∫§P

def get_connection():
    """T·∫°o k·∫øt n·ªëi ri√™ng cho m·ªói lu·ªìng (Timeout ng·∫Øn ƒë·ªÉ d·ªÖ tho√°t)"""
    return mysql.connector.connect(**DB_CONFIG, connection_timeout=5)

def process_batch(batch_data, thread_id):
    """H√†m x·ª≠ l√Ω m·ªôt l√¥ k·ªãch b·∫£n"""
    results = []
    
    # N·∫øu ƒë√£ c√≥ l·ªánh d·ª´ng th√¨ kh√¥ng m·ªü k·∫øt n·ªëi m·ªõi n·ªØa
    if stop_event.is_set(): return []

    conn = None
    try:
        conn = get_connection()
        cursor = conn.cursor()
        
        for row in batch_data:
            # 1. KI·ªÇM TRA C·ªú D·ª™NG LI√äN T·ª§C
            if stop_event.is_set(): 
                break # Tho√°t kh·ªèi v√≤ng l·∫∑p batch ngay l·∫≠p t·ª©c
            
            # G·∫Øn th·∫ª (Tagging)
            unique_tag = f"/* TAG:{uuid.uuid4().hex[:8]} */"
            tagged_query = f"{row['query']} {unique_tag}"
            
            exec_start = time.time()
            rows_sent = 0
            error_code = 0
            error_msg = ""
            
            try:
                cursor.execute(f"USE {row['database']}")
                cursor.execute(tagged_query)
                res = cursor.fetchall()
                rows_sent = len(res)
            except mysql.connector.Error as err:
                error_code = err.errno
                error_msg = err.msg
            except: pass
            
            # L·∫•y Metric th·∫≠t
            conn.commit() 
            metric_sql = f"""
            SELECT TRUNCATE(TIMER_WAIT/1000000000, 6) as exec_time, ROWS_AFFECTED
            FROM performance_schema.events_statements_history_long
            WHERE SQL_TEXT LIKE '%{unique_tag}%'
            ORDER BY EVENT_ID DESC LIMIT 1
            """
            cursor.execute(metric_sql)
            metric = cursor.fetchone()
            
            real_exec = metric[0] if metric else (time.time() - exec_start)
            real_aff = metric[1] if metric else 0
            
            # ƒê√≥ng g√≥i
            results.append({
                "timestamp": row['timestamp'],
                "user": row['user'],
                "client_ip": "192.168.1." + str(hash(row['user']) % 250),
                "database": row['database'],
                "query": row['query'],
                "execution_time_sec": float(real_exec),
                "rows_returned": rows_sent,
                "rows_affected": real_aff,
                "error_code": error_code,
                "error_message": str(error_msg),
                "is_anomaly": row['is_anomaly'],
                "source_dbms": "MySQL"
            })
            
    except Exception as e:
        # Ch·ªâ in l·ªói n·∫øu kh√¥ng ph·∫£i ƒëang d·ª´ng (ƒë·ªÉ ƒë·ª° r√°c m√†n h√¨nh)
        if not stop_event.is_set():
            with print_lock:
                print(f"\n‚ö†Ô∏è Thread {thread_id} Error: {e}")
    finally:
        if conn: 
            try: conn.close()
            except: pass
        
    return results

def run_fast_simulation():
    global total_processed
    
    print("üìñ ƒêang ƒë·ªçc file k·ªãch b·∫£n v√†o b·ªô nh·ªõ...")
    try:
        with open(SCENARIO_FILE, 'r', encoding='utf-8') as f:
            scenarios = list(csv.DictReader(f))
    except:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file k·ªãch b·∫£n CSV!")
        return

    total_rows = len(scenarios)
    print(f"üöÄ B·∫ÆT ƒê·∫¶U TƒÇNG T·ªêC (SAFE STOP MODE):")
    print(f"   - T·ªïng s·ªë d√≤ng: {total_rows}")
    print(f"   - S·ªë lu·ªìng: {NUM_THREADS}")
    print("üëâ Nh·∫•n CTRL+C b·∫•t c·ª© l√∫c n√†o ƒë·ªÉ D·ª™NG v√† L∆ØU k·∫øt qu·∫£.")
    print("------------------------------------------------")
    
    batches = [scenarios[i:i + BATCH_SIZE] for i in range(0, total_rows, BATCH_SIZE)]
    final_data = []
    start_time = time.time()
    
    # Executor qu·∫£n l√Ω lu·ªìng
    executor = ThreadPoolExecutor(max_workers=NUM_THREADS)
    
    try:
        # G·ª≠i vi·ªác cho th·ª£
        future_to_batch = {executor.submit(process_batch, batch, i): i for i, batch in enumerate(batches)}
        
        for future in as_completed(future_to_batch):
            # N·∫øu b·∫•m d·ª´ng, h·ªßy nh·∫≠n k·∫øt qu·∫£ ti·∫øp theo ƒë·ªÉ tho√°t nhanh
            if stop_event.is_set(): break
            
            batch_result = future.result()
            if batch_result:
                final_data.extend(batch_result)
                
                with print_lock:
                    total_processed += len(batch_result)
                    if total_processed % 500 == 0:
                        elapsed = time.time() - start_time
                        speed = total_processed / elapsed if elapsed > 0 else 0
                        print(f"\r‚ö° Progress: {total_processed}/{total_rows} | Speed: {speed:.1f} q/s | Time: {elapsed:.1f}s", end="")

    except KeyboardInterrupt:
        print("\n\nüõë ƒê√É NH·∫¨N L·ªÜNH D·ª™NG (CTRL+C)!")
        print("‚è≥ ƒêang ƒë·ª£i c√°c lu·ªìng ho√†n t·∫•t n·ªët c√¥ng vi·ªác d·ªü dang...")
        stop_event.set() # B·∫≠t c·ªù d·ª´ng
        executor.shutdown(wait=False) # Kh√¥ng nh·∫≠n th√™m vi·ªác m·ªõi
        
    # --- PH·∫¶N L∆ØU FILE (Lu√¥n ch·∫°y d√π xong hay b·ªã d·ª´ng gi·ªØa ch·ª´ng) ---
    if final_data:
        print(f"\n\nüíæ ƒêang l∆∞u {len(final_data)} d√≤ng d·ªØ li·ªáu v√†o '{FINAL_DATASET}'...")
        df = pd.DataFrame(final_data)
        df.sort_values(by='timestamp', inplace=True)
        df.to_csv(FINAL_DATASET, index=False)
        print(f"‚úÖ ƒê√É L∆ØU TH√ÄNH C√îNG! B·∫°n c√≥ th·ªÉ d√πng file n√†y ngay.")
    else:
        print("\n‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c thu th·∫≠p.")

    print(f"üëã K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.")

if __name__ == "__main__":
    # ƒê·∫£m b·∫£o Performance Schema b·∫≠t
    try:
        c = mysql.connector.connect(**DB_CONFIG)
        cur = c.cursor()
        cur.execute("UPDATE performance_schema.setup_consumers SET ENABLED='YES' WHERE NAME LIKE 'events_statements_history_long'")
        cur.execute("UPDATE performance_schema.setup_instruments SET ENABLED='YES', TIMED='YES' WHERE NAME LIKE 'statement/%'")
        c.commit()
        c.close()
    except: pass
    
    run_fast_simulation()