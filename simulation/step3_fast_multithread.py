# simulation/step3_fast_multithread.py
import mysql.connector
from mysql.connector import errorcode
import csv, time, uuid, threading, sys, math, re, random
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- C·∫§U H√åNH ---
SCENARIO_FILE = "simulation/scenario_script_30d.csv"
FINAL_DATASET = "final_dataset_30d.csv"
DB_CONFIG = {
    "user": "root",
    "password": "root", # <- Thay password c·ªßa b·∫°n
    "host": "localhost",
    "database": "mysql"
}

NUM_THREADS = 10      # S·ªë lu·ªìng ch·∫°y song song
BATCH_SIZE = 50       # K√≠ch th∆∞·ªõc m·ªói batch x·ª≠ l√Ω

print_lock = threading.Lock()
total_processed = 0
stop_event = threading.Event()

class NetworkForensicSimulator:
    """
    Tr√¨nh m√¥ ph·ªèng m·∫°ng "Stateful" & "Context-Aware".
    ƒê·∫£m b·∫£o t√≠nh nh·∫•t qu√°n c·ªßa Port/IP d·ª±a tr√™n h√†nh vi v√† lo·∫°i User.
    H·ªó tr·ª£ ƒëa lu·ªìng (Thread-Safe).
    """
    def __init__(self):
        self.lock = threading.Lock()
        self.user_pools = {}     # L∆∞u pool port cho Web/App users
        self.persistent_sessions = {} # L∆∞u port c·ªë ƒë·ªãnh cho Admin/Dev/Insider
        self.scan_state = 10000  # L∆∞u tr·∫°ng th√°i port scanning

    def get_socket_info(self, user, behavior_type):
        """
        Tr·∫£ v·ªÅ (client_ip, client_port) d·ª±a tr√™n ng·ªØ c·∫£nh.
        """
        with self.lock:
            # 1. X·ª¨ L√ù IP (Logic c≈© c·ªßa b·∫°n nh∆∞ng ƒë∆∞a v√†o ƒë√¢y cho g·ªçn)
            # M·∫∑c ƒë·ªãnh IP theo User Hash
            client_ip = f"192.168.1.{hash(user) % 250 + 1}"
            
            # N·∫øu l√† unknown_ip ho·∫∑c script_kiddie th√¨ IP ph·∫£i l·∫° ho·∫∑c random
            if user in ['unknown_ip', 'script_kiddie', 'apt_group_x']:
                client_ip = f"10.0.{random.randint(1,254)}.{random.randint(1,254)}"

            # 2. X·ª¨ L√ù PORT THEO H√ÄNH VI (Context-Aware)
            
            # NH√ìM A: SCANNING (Qu√©t c·ªïng)
            # Port tƒÉng d·∫ßn ƒë·ªÅu ƒë·ªÉ AI nh·∫≠n di·ªán pattern
            if behavior_type == 'SCANNING': 
                self.scan_state += 1
                if self.scan_state > 65000: self.scan_state = 10000
                return client_ip, self.scan_state

            # NH√ìM B: NOISY ATTACKS (DoS, Brute Force)
            # Random ho√†n to√†n ƒë·ªÉ gi·∫£ l·∫≠p connection storm
            if behavior_type in ['DOS', 'BRUTE_FORCE']:
                return client_ip, random.randint(10000, 65000)

            # NH√ìM C: PERSISTENT USERS (Admin, Dev, Insider Threat, Backdoor)
            # Gi·∫£ l·∫≠p c√¥ng c·ª• qu·∫£n tr·ªã (treo k·∫øt n·ªëi l√¢u d√†i)
            # Insider Threat ph·∫£i l·∫©n tr·ªën trong nh√≥m n√†y -> D√πng port c·ªë ƒë·ªãnh
            if any(role in user for role in ['admin', 'dev', 'dave', 'insider']) or behavior_type == 'PERSISTENCE_BACKDOOR':
                if user not in self.persistent_sessions:
                    # G√°n 1 port c·ªë ƒë·ªãnh cho phi√™n l√†m vi·ªác n√†y
                    self.persistent_sessions[user] = random.randint(10000, 60000)
                return client_ip, self.persistent_sessions[user]

            # NH√ìM D: APPLICATION POOLING (Sales, HR, SQL Injection)
            # ƒê√¢y l√† nh√≥m ƒë√¥ng nh·∫•t. SQL Injection ph·∫£i n·∫±m ·ªü ƒë√¢y th√¨ m·ªõi gi·ªëng th·∫≠t!
            # (Hacker b·∫Øn SQLi qua Web Browser -> Server Web d√πng Connection Pool n·ªëi v√†o DB)
            if user not in self.user_pools:
                # T·∫°o pool 5-8 ports cho user n√†y
                base = random.randint(10000, 60000)
                self.user_pools[user] = [base + i for i in range(random.randint(5, 8))]
            
            # Gi·∫£ l·∫≠p h√†nh vi l·∫•y connection t·ª´ pool
            # 95% d√πng l·∫°i port c≈©, 5% m·ªü port m·ªõi (recycle)
            pool = self.user_pools[user]
            if random.random() < 0.95:
                return client_ip, random.choice(pool)
            else:
                new_port = random.randint(10000, 65000)
                pool.pop(0) # B·ªè port c≈© nh·∫•t
                pool.append(new_port)
                return client_ip, new_port
            
# Kh·ªüi t·∫°o Simulator to√†n c·ª•c
net_sim = NetworkForensicSimulator()


# --- C√ÅC H√ÄM T√çNH TO√ÅN FEATURE (PYTHON SIDE) ---
def calculate_entropy(text):
    """T√≠nh ƒë·ªô h·ªón lo·∫°n (Shannon Entropy) c·ªßa chu·ªói query"""
    if not text: return 0
    prob = [float(text.count(c)) / len(text) for c in dict.fromkeys(list(text))]
    entropy = - sum([p * math.log(p) / math.log(2.0) for p in prob])
    return round(entropy, 4)

def analyze_query_structure(query):
    """Ph√¢n t√≠ch ng·ªØ c·∫£nh query"""
    q_lower = query.lower()
    
    # 1. Check System Tables
    is_system = 1 if any(x in q_lower for x in ['information_schema', 'mysql.', 'performance_schema', 'sys.']) else 0
    
    # 2. Count Tables (∆Ø·ªõc l∆∞·ª£ng s∆° b·ªô qua t·ª´ kh√≥a JOIN/FROM)
    # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa FROM v√† JOIN
    num_tables = len(re.findall(r'\bfrom\b|\bjoin\b', q_lower))
    if num_tables == 0 and ('select' in q_lower or 'update' in q_lower): num_tables = 1
    
    return is_system, num_tables

def get_connection():
    try:
        # Timeout k·∫øt n·ªëi 5s ƒë·ªÉ kh√¥ng ch·ªù l√¢u n·∫øu DB s·∫≠p
        return mysql.connector.connect(**DB_CONFIG, connection_timeout=5, autocommit=True)
    except: return None

def scrub_cursor(cursor):
    """V·ªá sinh cursor ƒë·ªÉ tr√°nh l·ªói Unread result found"""
    try:
        cursor.fetchall()
    except: pass
    try:
        while cursor.nextset():
            try: cursor.fetchall()
            except: pass
    except: pass

def process_batch(batch_data):
    if stop_event.is_set(): return []
    results = []
    conn = get_connection()
    if not conn: return []

    try:
        cursor = conn.cursor(buffered=True)
        
        # --- C·∫§U H√åNH PH√íNG TH·ª¶ CHO TOOL ---
        # Gi·ªõi h·∫°n th·ªùi gian ch·∫°y query l√† 2000ms (2s)
        # ƒê·ªÉ tr√°nh b·ªã treo khi ch·∫°y c√°c query t·∫•n c√¥ng nh∆∞ SLEEP(100) ho·∫∑c DoS
        cursor.execute("SET SESSION MAX_EXECUTION_TIME=2000") 
        
        for row in batch_data:
            if stop_event.is_set(): break
            
            # --- 1. CHU·∫®N B·ªä D·ªÆ LI·ªÜU ---
            # FIX: ƒê∆∞a tag l√™n ƒê·∫¶U query ƒë·ªÉ tr√°nh b·ªã c·∫Øt khi l∆∞u v√†o Performance Schema
            unique_tag = f"/* TAG:{uuid.uuid4().hex[:8]} */"
            tagged_query = f"{unique_tag} {row['query']}"
            
            entropy = calculate_entropy(row['query'])
            query_len = len(row['query'])
            is_sys, num_tbls = analyze_query_structure(row['query'])
            
            # --- G·ªåI SIMULATOR ƒê·ªÇ L·∫§Y IP/PORT ---
            behavior_type = row.get('behavior_type', 'NORMAL')
            client_ip, client_port = net_sim.get_socket_info(row['user'], behavior_type)
            
            # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh (ƒë√£ x√≥a l·ªói d·∫•u ph·∫©y tuple)
            rows_sent = 0
            rows_affected = 0
            exec_time_ms = 0.0 
            rows_examined = 0
            lock_time = 0.0
            tmp_disk = 0
            tmp_mem = 0
            digest = ""
            digest_text = ""
            errors = 0
            error_code = 0
            error_msg = ""
            real_exec = 0.0
            warnings = 0
            no_index = 0
            
            # --- 2. TH·ª∞C THI QUERY ---
            try:
                scrub_cursor(cursor)
                cursor.execute(f"USE {row['database']}")
                
                scrub_cursor(cursor)
                cursor.execute(tagged_query)
                
                if cursor.with_rows:
                    res = cursor.fetchall()
                    rows_sent = len(res)
                    rows_affected = 0
                else:
                    rows_sent = 0
                    rows_affected = cursor.rowcount
                    
            except mysql.connector.Error as err:
                error_code = err.errno
                error_msg = str(err.msg).replace('\n', ' ').replace('"', "'")
                if err.errno in [2006, 2013, 2014, 2055]: # M·∫•t k·∫øt n·ªëi th√¨ break batch
                    break 
            except Exception as e:
                error_code = 9999
                error_msg = str(e).replace('\n', ' ')
            finally:
                scrub_cursor(cursor)

            # --- 3. TR√çCH XU·∫§T METRICS (FORENSICS) ---
            try:
                metric_sql = f"""
                SELECT 
                    TIMER_WAIT / 1000000000000,   -- [0] exec_time (seconds)
                    LOCK_TIME / 1000000000000,    -- [1] lock_time
                    ROWS_EXAMINED,                -- [2]
                    ROWS_SENT,                    -- [3]
                    ROWS_AFFECTED,                -- [4]
                    CREATED_TMP_DISK_TABLES,      -- [5]
                    CREATED_TMP_TABLES,           -- [6]
                    DIGEST,                       -- [7]
                    DIGEST_TEXT,                  -- [8]
                    ERRORS,                       -- [9]
                    WARNINGS,                     -- [10]
                    NO_INDEX_USED                 -- [11]
                FROM performance_schema.events_statements_history_long
                WHERE SQL_TEXT LIKE '{unique_tag}%'
                ORDER BY EVENT_ID DESC LIMIT 1
                """
                cursor.execute(metric_sql)
                metric = cursor.fetchone()
                
                if metric:
                    real_exec = float(metric[0]) if metric[0] else 0.0
                    lock_time = float(metric[1]) if metric[1] else 0.0
                    
                    # FIX LOGIC: Rows Examined √≠t nh·∫•t ph·∫£i b·∫±ng Rows Sent (tr√°nh logic 0 examined)
                    raw_examined = int(metric[2]) if metric[2] else 0
                    raw_sent = int(metric[3]) if metric[3] is not None else 0
                    rows_examined = max(raw_examined, raw_sent)
                    
                    if metric[3] is not None: rows_sent = int(metric[3])
                    if metric[4] is not None: rows_affected = int(metric[4])
                    tmp_disk = int(metric[5]) if metric[5] else 0
                    tmp_mem = int(metric[6]) if metric[6] else 0
                    digest = str(metric[7]) if metric[7] else ""
                    digest_text = str(metric[8]) if metric[8] else ""
                    errors = int(metric[9]) if metric[9] is not None else (1 if error_code else 0)
                    warnings = int(metric[10]) if metric[10] is not None else 0
                    no_index = int(metric[11]) if metric[11] is not None else 0

                    # T√≠nh l·∫°i exec_time_ms ch√≠nh x√°c
                    exec_time_ms = real_exec * 1000

                    if error_code == 3024: error_msg = "Query execution time exceeded limit"
                
            except Exception: pass
            finally: scrub_cursor(cursor)

            # --- 4. GHI K·∫æT QU·∫¢ ---
            results.append({
                # --- Nh√≥m 1: Python t√≠nh ---
                "timestamp": row['timestamp'],
                "user": row['user'],
                "client_ip": client_ip,
                "client_port": client_port,
                "database": row['database'],
                "query": row['query'],
                "query_length": query_len,
                "entropy": entropy,
                "is_system_table": is_sys,
                "num_tables": num_tbls,

                # --- Nh√≥m 2: T·ª´ MySQL Metric ---
                "execution_time_sec": real_exec,
                "execution_time_ms": exec_time_ms,
                "lock_time_sec": lock_time,
                "rows_returned": rows_sent,
                "rows_examined": rows_examined,
                "rows_affected": rows_affected,
                "created_tmp_disk_tables": tmp_disk,
                "created_tmp_tables": tmp_mem,
                "query_digest": digest,
                "normalized_query": digest_text,     
                "warning_count": warnings,
                "no_index_used": no_index,
                
                # --- Nh√≥m 3: Error Handling ---
                "error_code": error_code,
                "error_message": error_msg,
                "error_count": errors,

                # --- Metadata kh√°c ---
                "is_anomaly": row['is_anomaly'],
                "behavior_type": row.get('behavior_type', 'NORMAL'),
                "source_dbms": "MySQL"
            })
            
    except Exception: pass
    finally:
        try:
            if 'cursor' in locals(): cursor.close()
            if conn.is_connected(): conn.close()
        except: pass
        
    return results

def run_simulation():
    global total_processed
    print(f"üìñ ƒêang ƒë·ªçc k·ªãch b·∫£n: {SCENARIO_FILE}...")
    try:
        with open(SCENARIO_FILE, 'r', encoding='utf-8') as f:
            scenarios = list(csv.DictReader(f))
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc file k·ªãch b·∫£n: {e}")
        return

    total_rows = len(scenarios)
    print(f"üöÄ B·∫ÆT ƒê·∫¶U CH·∫†Y SIMULATION ")
    print(f"   - T·ªïng s·ªë d√≤ng: {total_rows}")
    print(f"   - Threads: {NUM_THREADS}")
    print(f"   - Timeout b·∫£o v·ªá: 2 gi√¢y/query")
    
    batches = [scenarios[i:i + BATCH_SIZE] for i in range(0, total_rows, BATCH_SIZE)]
    final_data = []
    start_time = time.time()
    
    executor = ThreadPoolExecutor(max_workers=NUM_THREADS)
    try:
        futures = [executor.submit(process_batch, batch) for batch in batches]
        for future in as_completed(futures):
            if stop_event.is_set(): break
            try:
                res = future.result()
                if res:
                    final_data.extend(res)
                    with print_lock:
                        total_processed += len(res)
                        if total_processed % 200 == 0 or total_processed == total_rows:
                            elapsed = time.time() - start_time
                            speed = total_processed / elapsed if elapsed > 0 else 0
                            # In ƒë√® d√≤ng c≈© cho ƒë·∫πp
                            print(f"\r‚ö° Progress: {total_processed}/{total_rows} | Speed: {speed:.1f} q/s | Errors Detected: {len([x for x in final_data if x['error_code'] != 0])}", end="")
            except: pass
    except KeyboardInterrupt:
        print("\nüõë ƒêang d·ª´ng kh·∫©n c·∫•p...")
        stop_event.set()
        executor.shutdown(wait=False)
        
    if final_data:
        print(f"\n\nüíæ ƒêang l∆∞u file '{FINAL_DATASET}'...")
        df = pd.DataFrame(final_data)
        # S·∫Øp x·∫øp l·∫°i theo th·ªùi gian
        df.sort_values(by='timestamp', inplace=True)
        
        # L∆∞u file
        df.to_csv(FINAL_DATASET, index=False)
        print(f"‚úÖ HO√ÄN T·∫§T! File k·∫øt qu·∫£: {FINAL_DATASET}")
        print(f"   -> S·ªë c·ªôt: {len(df.columns)}")
    else:
        print("\n‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë∆∞·ª£c x·ª≠ l√Ω.")

if __name__ == "__main__":
    # B·∫≠t ch·∫ø ƒë·ªô theo d√µi c·ªßa MySQL tr∆∞·ªõc khi ch·∫°y
    try:
        print("üîß ƒêang c·∫•u h√¨nh MySQL Performance Schema...")
        c = mysql.connector.connect(**DB_CONFIG)
        cur = c.cursor()
        # B·∫≠t consumer l·ªãch s·ª≠ c√¢u l·ªánh
        cur.execute("UPDATE performance_schema.setup_consumers SET ENABLED='YES' WHERE NAME LIKE 'events_statements_history_long'")
        # B·∫≠t instrument ƒëo th·ªùi gian
        cur.execute("UPDATE performance_schema.setup_instruments SET ENABLED='YES', TIMED='YES' WHERE NAME LIKE 'statement/%'")
        c.commit()
        c.close()
    except Exception as e:
        print(f"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng th·ªÉ c·∫•u h√¨nh Performance Schema. S·ªë li·ªáu th·ªùi gian c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c. L·ªói: {e}")
        
    run_simulation()