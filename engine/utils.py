import pandas as pd
import os
import sqlglot
import sqlglot.expressions as exp
import sqlglot.errors as errors
import hashlib
import json
import re
from datetime import time as dt_time
import logging
import uuid
from datetime import datetime
from typing import Set
from redis import Redis, RedisError

# Th√™m c·∫•u h√¨nh logging ·ªü ƒë·∫ßu file
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [Utils] - %(message)s')

import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import *

# ==============================================================================
# I. C√ÅC H√ÄM H·ªñ TR·ª¢ PH√ÇN T√çCH THEO LU·∫¨T (RULE-BASED ANALYSIS)
# ==============================================================================
# C√°c h√†m trong m·ª•c n√†y cung c·∫•p logic c·ªët l√µi cho c√°c lu·∫≠t ph√°t hi·ªán b·∫•t th∆∞·ªùng.

def is_late_night_query(timestamp_obj, start_time_rule, end_time_rule):
    """
    Ki·ªÉm tra xem m·ªôt truy v·∫•n c√≥ ƒë∆∞·ª£c th·ª±c hi·ªán v√†o khung gi·ªù "ƒë√™m khuya" kh√¥ng.
    H√†m n√†y x·ª≠ l√Ω ƒë∆∞·ª£c c·∫£ tr∆∞·ªùng h·ª£p khung gi·ªù v∆∞·ª£t qua n·ª≠a ƒë√™m (v√≠ d·ª•: 22:00 - 05:00).
    """
    # L·∫•y ra ph·∫ßn th·ªùi gian (gi·ªù:ph√∫t:gi√¢y) t·ª´ ƒë·ªëi t∆∞·ª£ng datetime ƒë·∫ßy ƒë·ªß.
    query_time = timestamp_obj.time()
    
    # N·∫øu khung gi·ªù n·∫±m tr·ªçn trong m·ªôt ng√†y (v√≠ d·ª•: 01:00 - 05:00).
    if start_time_rule <= end_time_rule:
        return start_time_rule <= query_time < end_time_rule
    # N·∫øu khung gi·ªù v∆∞·ª£t qua n·ª≠a ƒë√™m (v√≠ d·ª•: 22:00 - 05:00 s√°ng h√¥m sau).
    else:
        # ƒêi·ªÅu ki·ªán l√†: th·ªùi gian l·ªõn h∆°n gi·ªù b·∫Øt ƒë·∫ßu (22:00) HO·∫∂C nh·ªè h∆°n gi·ªù k·∫øt th√∫c (05:00).
        return query_time >= start_time_rule or query_time < end_time_rule

def is_potential_large_dump(row, large_tables_list, threshold=1000):
    """
    Ph√°t hi·ªán h√†nh vi dump d·ªØ li·ªáu l·ªõn
    """
    # D√ôNG .at ƒê·ªÇ L·∫§Y GI√Å TR·ªä SCALAR ‚Äî AN TO√ÄN 100%
    try:
        rows_returned = int(row.at['rows_returned']) if pd.notna(row.at['rows_returned']) else 0
    except:
        rows_returned = 0

    try:
        query = str(row.at['query']).lower() if pd.notna(row.at['query']) else ""
    except:
        query = ""

    # Rule 1: R√µ r√†ng dump l·ªõn
    if rows_returned > threshold:
        return True

    # Rule 2: INTO OUTFILE / DUMPFILE
    if "into outfile" in query or "into dumpfile" in query:
        return True

    # Rule 3: SELECT * + b·∫£ng l·ªõn + kh√¥ng c√≥ WHERE
    if "select *" in query:
        has_where = "where" in query
        accesses_large = any(table.lower() in query for table in large_tables_list)
        if not has_where and accesses_large:
            return True

    return False

def is_sensitive_table_accessed(accessed_tables_list, sensitive_tables_list):
    """
    Ki·ªÉm tra xem danh s√°ch c√°c b·∫£ng b·ªã truy c·∫≠p c√≥ ch·ª©a b·∫•t k·ª≥ b·∫£ng nh·∫°y c·∫£m n√†o kh√¥ng.
    """
    # Tr·∫£ v·ªÅ False n·∫øu ƒë·∫ßu v√†o kh√¥ng ph·∫£i l√† m·ªôt danh s√°ch.
    if not isinstance(accessed_tables_list, list): 
        return False, []
        
    accessed_sensitive = [] # Danh s√°ch ƒë·ªÉ l∆∞u c√°c b·∫£ng nh·∫°y c·∫£m c·ª• th·ªÉ ƒë√£ b·ªã truy c·∫≠p.
    sensitive_tables_lower = [st.lower() for st in sensitive_tables_list] # Chu·∫©n h√≥a t√™n b·∫£ng nh·∫°y c·∫£m v·ªÅ ch·ªØ th∆∞·ªùng.
    
    # L·∫∑p qua c√°c b·∫£ng ƒë√£ b·ªã truy c·∫≠p.
    for table in accessed_tables_list:
        table_lower = table.lower()
        # L·∫•y t√™n b·∫£ng (b·ªè ph·∫ßn database n·∫øu c√≥)
        table_name_only = table_lower.split('.')[-1]
        
        # Ki·ªÉm tra c·∫£ t√™n ƒë·∫ßy ƒë·ªß v√† t√™n b·∫£ng ƒë∆°n gi·∫£n
        for sensitive in sensitive_tables_lower:
            sensitive_name_only = sensitive.split('.')[-1]
            # Match n·∫øu:
            # 1. T√™n ƒë·∫ßy ƒë·ªß kh·ªõp (mydb.users == mydb.users)
            # 2. T√™n b·∫£ng kh·ªõp (users == users ho·∫∑c mydb.users ends with users)
            if table_lower == sensitive or table_name_only == sensitive_name_only:
                accessed_sensitive.append(table)
                break
            
    # Tr·∫£ v·ªÅ m·ªôt tuple: (True/False, danh_s√°ch_b·∫£ng_nh·∫°y_c·∫£m_b·ªã_truy_c·∫≠p).
    return bool(accessed_sensitive), accessed_sensitive

# --- RULE M·ªöI (Gi·ªù ƒë√£ kh·∫£ thi) ---
def is_data_sabotage(row, threshold=100):
    """
    Ph√°t hi·ªán c√°c l·ªánh DELETE/UPDATE ·∫£nh h∆∞·ªüng ƒë·∫øn nhi·ªÅu h√†ng.
    """
    query_lower = str(row.get('query', '')).lower()
    rows_affected = row.get('rows_affected', 0)
    
    if rows_affected > threshold and ('delete' in query_lower or 'update' in query_lower):
        # Ki·ªÉm tra th√™m ƒë·ªÉ lo·∫°i b·ªè c√°c l·ªánh an to√†n (v√≠ d·ª•: kh√¥ng c√≥ WHERE)
        if 'where' not in query_lower:
            return True, "No WHERE clause"
        else:
            return True, f"High row count ({rows_affected})"
            
    return False, None

# --- RULE M·ªöI (Gi·ªù ƒë√£ kh·∫£ thi) ---
def is_dos_attack(row, time_threshold_ms=15000): # 15 gi√¢y
    """
    Ph√°t hi·ªán c√°c truy v·∫•n ch·∫°y qu√° ch·∫≠m (T·∫•n c√¥ng DoS)
    """
    exec_time = row.get('execution_time_ms', 0)
    
    if exec_time > time_threshold_ms:
        return True, f"Query took {exec_time:.0f} ms"
    return False, None

def analyze_sensitive_access(row, sensitive_tables_list, allowed_users_list,
                             safe_start, safe_end, safe_days):

    accessed_tables = row.get('accessed_tables', [])
    user = row.get('user')
    timestamp = row.get('timestamp')

    if accessed_tables is None:
        accessed_tables = []
    
    # N·∫øu accessed_tables l√† chu·ªói (do ƒë·ªçc t·ª´ CSV/DB l√™n), c·∫ßn eval l·∫°i
    if isinstance(accessed_tables, str):
        try:
            import ast
            accessed_tables = ast.literal_eval(accessed_tables)
        except:
            accessed_tables = []

    is_sensitive_hit, specific_sensitive_tables = is_sensitive_table_accessed(accessed_tables, sensitive_tables_list)

    # N·∫øu kh√¥ng truy c·∫≠p b·∫£ng nh·∫°y c·∫£m, b·ªè qua
    if not is_sensitive_hit:
        return None

    # Ki·ªÉm tra c√°c ƒëi·ªÅu ki·ªán
    user_is_allowed = (not pd.isna(user) and user in allowed_users_list)
    is_outside_safe_hours = not (safe_start <= timestamp.hour < safe_end and timestamp.weekday() in safe_days)

    # L·ªñ H·ªîNG L√Ä ·ªû ƒê√ÇY. Logic c≈© c·ªßa b·∫°n l√† `if user_is_allowed: return None`.
    # Logic ƒê√öNG l√†:

    # CH·ªà COI L√Ä H·ª¢P L·ªÜ (return None) N·∫æU
    # user ƒë∆∞·ª£c ph√©p V√Ä truy c·∫≠p TRONG gi·ªù an to√†n.
    if user_is_allowed and not is_outside_safe_hours:
        return None

    # T·∫•t c·∫£ c√°c tr∆∞·ªùng h·ª£p kh√°c ƒë·ªÅu l√† b·∫•t th∆∞·ªùng.
    # X√¢y d·ª±ng l√Ω do:
    anomaly_reasons = []
    if not user_is_allowed:
        anomaly_reasons.append(f"User '{user if not pd.isna(user) else 'N/A'}' kh√¥ng c√≥ trong danh s√°ch ƒë∆∞·ª£c ph√©p.")
    if is_outside_safe_hours:
        anomaly_reasons.append("Truy c·∫≠p ngo√†i gi·ªù l√†m vi·ªác an to√†n.")

    return {
        "reason": " ".join(anomaly_reasons) + f" [Tables: {', '.join(specific_sensitive_tables)}]",
        "accessed_sensitive_tables_list": specific_sensitive_tables
    }


def check_unusual_user_activity_time(row, user_profiles_dict):
    """Ki·ªÉm tra xem ho·∫°t ƒë·ªông c·ªßa ng∆∞·ªùi d√πng c√≥ n·∫±m ngo√†i gi·ªù ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng c·ªßa h·ªç kh√¥ng."""
    user = row['user']
    timestamp = row['timestamp']
    
    # B·ªè qua n·∫øu kh√¥ng c√≥ th√¥ng tin user ho·∫∑c user ch∆∞a c√≥ h·ªì s∆° ho·∫°t ƒë·ªông.
    if pd.isna(user) or user not in user_profiles_dict: 
        return None 
    
    # L·∫•y h·ªì s∆° ho·∫°t ƒë·ªông c·ªßa user.
    profile = user_profiles_dict[user]
    current_hour = timestamp.hour
    
    # Ki·ªÉm tra xem gi·ªù hi·ªán t·∫°i c√≥ n·∫±m ngo√†i kho·∫£ng th·ªùi gian ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng kh√¥ng.
    if 'active_start' in profile and 'active_end' in profile:
        if not (profile['active_start'] <= current_hour < profile['active_end'] + 1):
            return f"Ngo√†i gi·ªù Ho·∫°t ƒê·ªông th∆∞·ªùng l·ªá c·ªßa user ({profile['active_start']:02d}:00 - {profile['active_end']+1:02d}:00)"
            
    # N·∫øu n·∫±m trong gi·ªù b√¨nh th∆∞·ªùng, tr·∫£ v·ªÅ None.
    return None

# --- RULE M·ªöI: PH√ÅT HI·ªÜN H√ÄM NGHI V·∫§N (SQLi) ---
def is_suspicious_function_used(query: str):
    """
    Ki·ªÉm tra query c√≥ ch·ª©a c√°c h√†m ƒë√°ng ng·ªù th∆∞·ªùng d√πng trong SQLi/Exfiltration.
    Tr·∫£ v·ªÅ (bool, str) - (C√≥ ƒë√°ng ng·ªù kh√¥ng, T√™n h√†m ƒë√°ng ng·ªù)
    """
    if pd.isna(query):
        return False, None
    query_lower = str(query).lower()
    for func in SUSPICIOUS_FUNCTIONS:
        if f"{func}(" in query_lower:
            return True, func
    return False, None

# --- RULE M·ªöI: PH√ÅT HI·ªÜN THAY ƒê·ªîI QUY·ªÄN (DCL/DDL) ---
def is_privilege_change(query: str):
    """
    Ki·ªÉm tra query c√≥ ph·∫£i l√† l·ªánh thay ƒë·ªïi quy·ªÅn ho·∫∑c user kh√¥ng.
    Tr·∫£ v·ªÅ (bool, str) - (C√≥ thay ƒë·ªïi kh√¥ng, L·ªánh)
    """
    if pd.isna(query):
        return False, None
    query_lower = str(query).lower().strip()
    for cmd in PRIVILEGE_COMMANDS:
        if query_lower.startswith(cmd):
            return True, cmd
    return False, None

# ==============================================================================
# II. C√ÅC H√ÄM H·ªñ TR·ª¢ FEATURE ENGINEERING V√Ä FEEDBACK
# ==============================================================================
# C√°c h√†m trong m·ª•c n√†y h·ªó tr·ª£ vi·ªác tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng cho AI v√† x·ª≠ l√Ω feedback.

def get_tables_with_sqlglot(sql_query):
    """Tr√≠ch xu·∫•t t√™n c√°c b·∫£ng t·ª´ m·ªôt c√¢u l·ªánh SQL s·ª≠ d·ª•ng th∆∞ vi·ªán sqlglot."""
    tables = set() # D√πng set ƒë·ªÉ t·ª± ƒë·ªông lo·∫°i b·ªè c√°c t√™n b·∫£ng tr√πng l·∫∑p.
    
    # Tr·∫£ v·ªÅ danh s√°ch r·ªóng n·∫øu query kh√¥ng h·ª£p l·ªá.
    if pd.isna(sql_query) or not isinstance(sql_query, str) or not sql_query.strip():
        return []
        
    try:
        # Ph√¢n t√≠ch c√∫ ph√°p c√¢u l·ªánh SQL theo dialect c·ªßa MySQL.
        parsed_expression = sqlglot.parse_one(sql_query, read='mysql')
        if parsed_expression:
            # T√¨m t·∫•t c·∫£ c√°c node l√† Table trong c√¢y c√∫ ph√°p tr·ª´u t∆∞·ª£ng.
            for table_node in parsed_expression.find_all(exp.Table):
                final_table_name = table_node.name
                # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p t√™n b·∫£ng c√≥ alias.
                if hasattr(table_node, 'this') and table_node.this and isinstance(table_node.this, exp.Identifier):
                     final_table_name = table_node.this.name
                if final_table_name:
                    tables.add(final_table_name.lower()) # Chu·∫©n h√≥a v·ªÅ ch·ªØ th∆∞·ªùng.
    except (errors.ParseError, Exception):
        # B·ªè qua n·∫øu sqlglot kh√¥ng th·ªÉ ph√¢n t√≠ch c√∫ ph√°p c√¢u l·ªánh ƒë·ªÉ ch∆∞∆°ng tr√¨nh kh√¥ng b·ªã d·ª´ng.
        pass
        
    return list(tables)

def extract_query_features(sql_query):
    """
    Tr√≠ch xu·∫•t m·ªôt t·∫≠p h·ª£p c√°c ƒë·∫∑c tr∆∞ng s·ªë h·ªçc t·ª´ m·ªôt c√¢u l·ªánh SQL.
    S·ª≠ d·ª•ng sqlglot ƒë·ªÉ ph√¢n t√≠ch c√∫ ph√°p m·ªôt c√°ch hi·ªáu qu·∫£ v√† an to√†n.
    Tr·∫£ v·ªÅ m·ªôt dictionary c√°c ƒë·∫∑c tr∆∞ng s·ªë h·ªçc.
    """
    # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh cho t·∫•t c·∫£ c√°c ƒë·∫∑c tr∆∞ng
    features = {
        'num_joins': 0,
        'num_where_conditions': 0,
        'num_group_by_cols': 0,
        'num_order_by_cols': 0,
        'has_limit': 0,
        'has_subquery': 0,
        'has_union': 0,
        'has_where': 0
    }
    
    # Tr·∫£ v·ªÅ m·∫∑c ƒë·ªãnh n·∫øu query kh√¥ng h·ª£p l·ªá
    if pd.isna(sql_query) or not isinstance(sql_query, str) or not sql_query.strip():
        return features

    try:
        parsed = sqlglot.parse_one(sql_query, read='mysql')
        if parsed:
            # === K·ªπ thu·∫≠t t·ªëi ∆∞u t·ª´ code c·ªßa b·∫°n b·∫°n ===
            # ƒê·∫øm s·ªë l∆∞·ª£ng JOIN
            features['num_joins'] = sum(1 for _ in parsed.find_all(exp.Join))
            # Ki·ªÉm tra s·ª± t·ªìn t·∫°i (hi·ªáu qu·∫£ h∆°n .find is not None)
            features['has_limit'] = 1 if parsed.find(exp.Limit) else 0
            features['has_subquery'] = 1 if parsed.find(exp.Subquery) else 0
            features['has_union'] = 1 if parsed.find(exp.Union) else 0
            
            # === Tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng chi ti·∫øt h∆°n ===
            # ƒê·∫øm s·ªë l∆∞·ª£ng ƒëi·ªÅu ki·ªán trong WHERE
            where_clause = parsed.find(exp.Where)
            if where_clause:
                features['has_where'] = 1
                # ∆Ø·ªõc t√≠nh s·ªë ƒëi·ªÅu ki·ªán b·∫±ng c√°ch ƒë·∫øm c√°c to√°n t·ª≠ logic
                # (AND, OR) v√† c·ªông 1. find_all nhanh h∆°n walk() cho m·ª•c ƒë√≠ch n√†y.
                # conditions = len(where_clause.find_all(exp.And, exp.Or))
                # ƒê·∫øm s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ m√† kh√¥ng c·∫ßn t·∫°o list
                conditions = sum(1 for _ in where_clause.find_all(exp.And, exp.Or))
                features['num_where_conditions'] = conditions + 1
            
            # ƒê·∫øm s·ªë c·ªôt trong GROUP BY
            group_by_clause = parsed.find(exp.Group)
            if group_by_clause:
                # `group_by_clause.expressions` l√† danh s√°ch c√°c c·ªôt
                features['num_group_by_cols'] = len(group_by_clause.expressions)

            # ƒê·∫øm s·ªë c·ªôt trong ORDER BY
            order_by_clause = parsed.find(exp.Order)
            if order_by_clause:
                features['num_order_by_cols'] = len(order_by_clause.expressions)
            
    except errors.ParseError:
        # N·∫øu sqlglot kh√¥ng parse ƒë∆∞·ª£c, gi·ªØ nguy√™n gi√° tr·ªã m·∫∑c ƒë·ªãnh
        pass
    except Exception:
        # B·∫Øt c√°c l·ªói kh√¥ng l∆∞·ªùng tr∆∞·ªõc kh√°c
        pass
        
    return features

def save_feedback_to_csv(item_data: dict, label: int) -> tuple[bool, str]:
    try:
        # item_data ƒë√£ l√† dict:
        identifier_string = f"{item_data.get('timestamp')}{item_data.get('user')}{item_data.get('query')}"
        feedback_id = hashlib.md5(str(identifier_string).encode()).hexdigest()

        new_feedback_data = dict(item_data)  # clone dict
        new_feedback_data['feedback_id'] = feedback_id
        new_feedback_data['is_anomaly_label'] = label

        for k, v in list(new_feedback_data.items()):
            if isinstance(v, (list, tuple)):
                new_feedback_data[k] = json.dumps(v, ensure_ascii=False)

        # ƒë·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
        os.makedirs(os.path.dirname(FEEDBACK_FILE_PATH) or ".", exist_ok=True)

        df_feedback = pd.DataFrame()
        if os.path.exists(FEEDBACK_FILE_PATH) and os.path.getsize(FEEDBACK_FILE_PATH) > 0:
            df_feedback = pd.read_csv(FEEDBACK_FILE_PATH)

        message = ""
        if (not df_feedback.empty and
            'feedback_id' in df_feedback.columns and
            feedback_id in df_feedback['feedback_id'].values):
            message = f"ƒê√£ C·∫¨P NH·∫¨T ph·∫£n h·ªìi cho m·ª•c #{feedback_id[:8]}..."
            idx = df_feedback.index[df_feedback['feedback_id'] == feedback_id][0]
            for col, value in new_feedback_data.items():
                if col in df_feedback.columns:
                    df_feedback.loc[idx, col] = value
                else:
                    df_feedback[col] = pd.NA
                    df_feedback.loc[idx, col] = value
        else:
            message = f"ƒê√£ GHI NH·∫¨N ph·∫£n h·ªìi m·ªõi cho m·ª•c #{feedback_id[:8]}..."
            new_row_df = pd.DataFrame([new_feedback_data])
            df_feedback = pd.concat([df_feedback, new_row_df], ignore_index=True)

        ordered_cols = ['feedback_id', 'timestamp', 'user', 'query', 'is_anomaly_label']
        all_columns = sorted(list(set(df_feedback.columns.tolist() + list(new_feedback_data.keys()))))
        final_cols = [c for c in ordered_cols if c in all_columns] + [c for c in all_columns if c not in ordered_cols]

        df_feedback.to_csv(FEEDBACK_FILE_PATH, mode='w', header=True, index=False, columns=final_cols, encoding='utf-8')
        logging.info(message)
        return True, message
    except Exception as e:
        logging.error(f"ƒê√£ x·∫£y ra l·ªói khi l∆∞u ph·∫£n h·ªìi: {e}")
        import traceback; traceback.print_exc()
        return False, f"ƒê√£ x·∫£y ra l·ªói khi l∆∞u ph·∫£n h·ªìi: {e}"

        
def update_config_file(new_configs: dict):
    """
    ƒê·ªçc file config.py, t√¨m v√† thay th·∫ø c√°c gi√° tr·ªã m·∫∑c ƒë·ªãnh, v√† ghi ƒë√® l·∫°i file.

    Args:
        new_configs (dict): M·ªôt dictionary ch·ª©a c√°c gi√° tr·ªã m·ªõi c·∫ßn c·∫≠p nh·∫≠t.

    Returns:
        tuple: (bool, str) - (Th√†nh c√¥ng/Th·∫•t b·∫°i, Th√¥ng b√°o)
    """
    config_path = 'config.py' # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file config.py trong c√πng th∆∞ m·ª•c
    try:
        # ƒê·ªçc t·∫•t c·∫£ c√°c d√≤ng c·ªßa file v√†o m·ªôt danh s√°ch
        with open(config_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        new_lines = []
        # L·∫∑p qua t·ª´ng d√≤ng ƒë·ªÉ x·ª≠ l√Ω
        for line in lines:
            # D√πng regex ƒë·ªÉ t√¨m c√°c d√≤ng g√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh
            # V√≠ d·ª•: LATE_NIGHT_START_TIME_DEFAULT = time(0, 0)
            match = re.match(r'^([A-Z_]+_DEFAULT)\s*=\s*(.*)', line)
            
            # N·∫øu d√≤ng hi·ªán t·∫°i l√† m·ªôt d√≤ng g√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh
            if match:
                var_name = match.group(1) # L·∫•y t√™n bi·∫øn, v√≠ d·ª•: LATE_NIGHT_START_TIME_DEFAULT
                
                # N·∫øu bi·∫øn n√†y c√≥ trong danh s√°ch c·∫ßn c·∫≠p nh·∫≠t
                if var_name in new_configs:
                    new_value = new_configs[var_name]
                    
                    # ƒê·ªãnh d·∫°ng l·∫°i gi√° tr·ªã m·ªõi th√†nh m·ªôt chu·ªói Python h·ª£p l·ªá
                    if isinstance(new_value, str):
                        # Chu·ªói ph·∫£i ƒë∆∞·ª£c ƒë·∫∑t trong d·∫•u ngo·∫∑c k√©p
                        new_line = f'{var_name} = r"{new_value}"\n' if '\\' in new_value else f'{var_name} = "{new_value}"\n'
                    elif isinstance(new_value, dt_time):
                        # ƒê·ªëi t∆∞·ª£ng time c·∫ßn ƒë∆∞·ª£c t√°i t·∫°o b·∫±ng time(...)
                        new_line = f"{var_name} = dt_time({new_value.hour}, {new_value.minute}, {new_value.second})\n"
                    elif isinstance(new_value, list):
                        # str(my_list) s·∫Ω t·∫°o ra m·ªôt chu·ªói nh∆∞ "['item1', 'item2']" tr√™n m·ªôt d√≤ng.
                        new_line = f"{var_name} = {str(new_value)}\n"
                    else:
                        # C√°c ki·ªÉu d·ªØ li·ªáu kh√°c (int, float)
                        new_line = f'{var_name} = {new_value}\n'
                    
                    # Th√™m d√≤ng m·ªõi ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng v√†o danh s√°ch `new_lines`
                    new_lines.append(new_line)
                    print(f"ƒêang c·∫≠p nh·∫≠t {var_name}...")
                else:
                    # N·∫øu bi·∫øn n√†y kh√¥ng c·∫ßn c·∫≠p nh·∫≠t, gi·ªØ nguy√™n d√≤ng c≈©
                    new_lines.append(line)
            else:
                # Gi·ªØ nguy√™n c√°c d√≤ng kh√¥ng ph·∫£i l√† d√≤ng g√°n gi√° tr·ªã (v√≠ d·ª•: comment, import,...)
                new_lines.append(line)

        # Ghi ƒë√® l·∫°i to√†n b·ªô file config.py v·ªõi n·ªôi dung m·ªõi
        # Ch·∫ø ƒë·ªô 'w' (write) s·∫Ω t·ª± ƒë·ªông x√≥a n·ªôi dung c≈© tr∆∞·ªõc khi ghi
        with open(config_path, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)
            
        return True, "L∆∞u c·∫•u h√¨nh m·∫∑c ƒë·ªãnh th√†nh c√¥ng!"

    except Exception as e:
        # B·∫Øt l·ªói v√† in ra ƒë·ªÉ d·ªÖ d√†ng g·ª° l·ªói
        import traceback
        traceback.print_exc()
        return False, f"L·ªói khi l∆∞u c·∫•u h√¨nh: {e}"


def save_logs_to_parquet(records: list, source_dbms: str) -> int:
    if not records:
        return 0
    try:
        df = pd.DataFrame(records)
        if 'source_dbms' not in df.columns:
            df['source_dbms'] = source_dbms
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)

        os.makedirs(STAGING_DATA_DIR, exist_ok=True)  # <-- th√™m d√≤ng n√†y

        filename = f"{source_dbms}_{datetime.now().strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:8]}.parquet"
        file_path = os.path.join(STAGING_DATA_DIR, filename)
        df.to_parquet(file_path, engine='pyarrow', index=False)
        logging.info(f"ƒê√£ l∆∞u {len(df)} b·∫£n ghi t·ª´ '{source_dbms}' v√†o file: {filename}")
        return len(df)
    except Exception as e:
        logging.error(f"L·ªói khi l∆∞u file Parquet: {e}")
        return 0

def get_normalized_query(query: str) -> str:
    """Extract DIGEST_TEXT-like normalized query"""
    if not query:
        return ""
    # Simple normalization (you can use sqlglot for better)
    query = re.sub(r'"\w+"', '"?"', query)
    query = re.sub(r"'\w+'", "'?'", query)
    query = re.sub(r'\d+', '?', query)
    return query.strip()

def count_sensitive_tables(tables: list) -> int:
    if not tables:
        return 0
    return len([t for t in tables if any(st in t.lower() for st in SENSITIVE_TABLES)])

def is_late_night(ts):
    from datetime import datetime
    if isinstance(ts, str):
        ts = datetime.fromisoformat(ts.replace("Z", "+00:00"))
    return ts.hour <= 5 or ts.hour >= 23


# ============================================================
# ACTIVE RESPONSE AUDIT LOGGER
# ============================================================

# C·∫•u h√¨nh logger
audit_logger = logging.getLogger('ActiveResponseAudit')
audit_logger.setLevel(logging.INFO)
audit_logger.propagate = False

# Ch·ªâ th√™m handler n·∫øu n√≥ ch∆∞a c√≥ ƒë·ªÉ tr√°nh log l·∫∑p l·∫°i
if not audit_logger.hasHandlers():
    try:
        # S·ª≠ d·ª•ng 'a' ƒë·ªÉ ghi n·ªëi ti·∫øp, 'utf-8'
        file_handler = logging.FileHandler(ACTIVE_RESPONSE_AUDIT_LOG_PATH, mode='a', encoding='utf-8')
        # ƒê·ªãnh d·∫°ng log: th·ªùi gian v√† n·ªôi dung
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
        audit_logger.addHandler(file_handler)
    except Exception as e:
        print(f"L·ªñI: Kh√¥ng th·ªÉ t·∫°o file audit log t·∫°i {ACTIVE_RESPONSE_AUDIT_LOG_PATH}: {e}")

def log_active_response_action(action: str, target: str, reason: str):
    """
    Ghi l·∫°i m·ªôt h√†nh ƒë·ªông ph·∫£n ·ª©ng ch·ªß ƒë·ªông v√†o file audit log.

    Args:
        action (str): Lo·∫°i h√†nh ƒë·ªông (v√≠ d·ª•: "LOCK_ACCOUNT", "KILL_SESSION").
        target (str): ƒê·ªëi t∆∞·ª£ng b·ªã t√°c ƒë·ªông (v√≠ d·ª•: "user@host", "Session 123").
        reason (str): L√Ω do th·ª±c hi·ªán.
    """
    try:
        message = f"ACTION: {action} | TARGET: {target} | REASON: {reason}"
        audit_logger.info(message)
        for handler in audit_logger.handlers:
            handler.flush()
    except Exception as e:
        print(f"[Active Response] L·ªói khi ghi audit log: {e}")

def generate_html_alert(violation_summary: list):
    """
    T·∫°o n·ªôi dung HTML cho email c·∫£nh b√°o.
    Args:
        violation_summary: List c√°c dict [{'title': 'Gi·ªù Khuya', 'count': 4, 'time': '...', 'desc': '...'}]
    """

    # CSS Inline
    html_template = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <style>
            body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; color: #333; }}
            .container {{ max_width: 600px; margin: 0 auto; padding: 20px; background-color: #f9f9f9; }}
            .header {{ background-color: #d32f2f; color: white; padding: 20px; text-align: center; border-radius: 5px 5px 0 0; }}
            .alert-box {{ background-color: #fff; padding: 20px; border: 1px solid #ddd; border-top: none; border-radius: 0 0 5px 5px; }}
            .stat-box {{ background-color: #fff3cd; border-left: 5px solid #ffc107; padding: 15px; margin-bottom: 20px; }}
            table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
            th {{ background-color: #f2f2f2; text-align: left; padding: 10px; border-bottom: 2px solid #ddd; font-size: 12px; text-transform: uppercase; color: #555; }}
            td {{ padding: 12px 10px; border-bottom: 1px solid #eee; font-size: 14px; }}
            .severity-high {{ color: #d32f2f; font-weight: bold; }}
            .footer {{ text-align: center; font-size: 12px; color: #777; margin-top: 20px; }}
            .btn {{ display: inline-block; background-color: #d32f2f; color: white; padding: 10px 20px; text-decoration: none; border-radius: 3px; margin-top: 20px; font-weight: bold; }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h2 style="margin:0;">üö® Security Alert Triggered</h2>
                <p style="margin:5px 0 0 0; font-size: 14px;">UEBA Detection System</p>
            </div>

            <div class="alert-box">
                <p>The UEBA system has detected abnormal behaviors that require your attention.</p>

                <div class="stat-box">
                    <strong>Overview:</strong> Detected <strong>{len(violation_summary)}</strong> type/s of anomalies in the latest scan.
                </div>

                <table width="100%">
                    <thead>
                        <tr>
                            <th>Anomaly Type</th>
                            <th style="text-align: center;">Count</th>
                            <th>Entity (User@IP)</th>
                            <th>Occurrence (First - Last)</th>
                        </tr>
                    </thead>
                    <tbody>
    """

    # Loop ƒë·ªÉ t·∫°o c√°c d√≤ng trong b·∫£ng
    for item in violation_summary:
        html_template += f"""
            <tr>
                <td>
                    <span class="severity-high">{item['title']}</span><br>
                    <span style="font-size: 11px; color: #777;">{item['desc']}</span>
                </td>
                <td style="text-align: center;"><strong>{item['count']}</strong></td>
                <td style="font-size: 13px; color: #333;">
                    {item['target_str']}
                </td>
                <td style="font-size: 13px; white-space: nowrap;">
                    {item['time_range']}
                </td>
            </tr>
        """
    html_template += """
                    </tbody>
                </table>

            </div>

            <div class="footer" style="
                margin-top: 25px;
                text-align: center;
                background: #f5f5f5;
                padding: 15px 10px;
                border-top: 2px solid #d0d0d0;
                font-size: 12px;
                font-style: italic;
                color: #555;
            ">
                <p>
                    This is an automated email from the UEBA Platform system.<br>
                    Please do not reply to this email.
                </p>
            </div>

        </div>
    </body>
    </html>
    """
    return html_template

# ==============================================================================
# REDIS CONFIGURATION HELPER
# ==============================================================================

def configure_redis_for_reliability(redis_client: Redis) -> bool:
    """
    Configure Redis for better reliability and handle MISCONF errors.
    
    Returns:
        bool: True if configuration was successful, False otherwise
    """
    try:
        # Strategy 1: Use AOF instead of RDB for better persistence
        try:
            redis_client.config_set("save", "")  # Disable RDB snapshots
            logging.info("‚úÖ Redis: Disabled RDB snapshots")
            
            redis_client.config_set("appendonly", "yes")  # Enable AOF
            logging.info("‚úÖ Redis: Enabled AOF persistence")
            
            return True
            
        except Exception as config_error:
            logging.warning(f"‚ö†Ô∏è Could not configure Redis persistence: {config_error}")
            
            # Strategy 2: Fallback - disable the error check
            try:
                redis_client.config_set("stop-writes-on-bgsave-error", "no")
                logging.warning("‚ö†Ô∏è Redis: Disabled RDB error checking (fallback)")
                return True
                
            except Exception as fallback_error:
                logging.warning(f"‚ö†Ô∏è Redis: Could not modify config: {fallback_error}")
                return False
                
    except Exception as e:
        logging.error(f"‚ùå Redis configuration failed: {e}")
        return False

def handle_redis_misconf_error(error_msg: str) -> str:
    """
    Provide helpful error message and suggestions for MISCONF errors.
    
    Args:
        error_msg: The Redis error message
        
    Returns:
        str: Helpful suggestion message
    """
    if "MISCONF" in error_msg:
        return (
            "üí° Redis MISCONF Error Solutions:\n"
            "   1. Check disk space: df -h\n"
            "   2. Check Redis logs: tail -f /var/log/redis/redis-server.log\n"
            "   3. Fix permissions: sudo chown redis:redis /var/lib/redis\n"
            "   4. Disable RDB: redis-cli CONFIG SET save ''\n"
            "   5. Enable AOF: redis-cli CONFIG SET appendonly yes"
        )
    return "Check Redis server status and logs"